{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu4BbDusimkbZax0lNx99R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ygopishetty/dolfin_fe/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1fjgb8WExNl4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User Intent\n",
        "intents = [    {        \"tag\": \"greeting\",        \"patterns\": [\"Hi there\", \"Hello\", \"Greetings\", \"Hi\", \"Hey\"],\n",
        "        \"responses\": [\"Hello!\", \"Hi there! How can I help you?\", \"Hey! How can I assist you today?\"]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"goodbye\",\n",
        "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
        "        \"responses\": [\"Goodbye!\", \"See you soon!\", \"Take care!\"]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"thanks\",\n",
        "        \"patterns\": [\"Thanks\", \"Thank you\", \"Thanks a lot\"],\n",
        "        \"responses\": [\"You're welcome!\", \"No problem!\", \"Glad to help!\"]\n",
        "    },\n",
        "    \n",
        "    # Add more intents here \n",
        "]"
      ],
      "metadata": {
        "id": "18bfV88jx4D2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract data from intents\n",
        "words = []\n",
        "labels = []\n",
        "docs_x = []\n",
        "docs_y = []\n",
        "for intent in intents:\n",
        "    for pattern in intent['patterns']:\n",
        "        # Tokenize each word in pattern\n",
        "        w = pattern.split()\n",
        "        words.extend(w)\n",
        "        docs_x.append(w)\n",
        "        docs_y.append(intent['tag'])\n",
        "\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])"
      ],
      "metadata": {
        "id": "4TFgWTFnx8Y5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stem and lower case words\n",
        "stemmer = PorterStemmer()\n",
        "words = [stemmer.stem(w.lower()) for w in words]\n",
        "words = sorted(list(set(words)))\n"
      ],
      "metadata": {
        "id": "ZzNHQW7iyAMq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort labels\n",
        "labels = sorted(labels)\n"
      ],
      "metadata": {
        "id": "iunSeTwLywn5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training data\n",
        "training = []\n",
        "output = []\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "for x, doc in enumerate(docs_x):\n",
        "    bag = []\n",
        "\n",
        "    for w in words:\n",
        "        if w in doc:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)"
      ],
      "metadata": {
        "id": "g0gzrQa-y1ZF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert training data to numpy arrays\n",
        "training = np.array(training)\n",
        "output = np.array(output)\n"
      ],
      "metadata": {
        "id": "czA9FmWwy5B5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, input_shape=(len(training[0]),), activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(output[0]), activation='softmax')\n",
        "    ])"
      ],
      "metadata": {
        "id": "zytnpUPky85k"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "O_Tas1mIzHkJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(training, output, epochs=100, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb8DitEPzLTs",
        "outputId": "8ffe5cdb-0b00-4544-d7b0-c0f77b43ab06"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 7ms/step - loss: 1.0899 - accuracy: 0.3636\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1278 - accuracy: 0.2727\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0574 - accuracy: 0.6364\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0779 - accuracy: 0.4545\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0345 - accuracy: 0.6364\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1168 - accuracy: 0.4545\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0274 - accuracy: 0.4545\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0410 - accuracy: 0.6364\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0305 - accuracy: 0.5455\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0916 - accuracy: 0.3636\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0479 - accuracy: 0.4545\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9807 - accuracy: 0.7273\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0557 - accuracy: 0.5455\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0562 - accuracy: 0.4545\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0874 - accuracy: 0.4545\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0419 - accuracy: 0.6364\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9862 - accuracy: 0.6364\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0410 - accuracy: 0.5455\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0150 - accuracy: 0.6364\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0864 - accuracy: 0.4545\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9633 - accuracy: 0.7273\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0003 - accuracy: 0.6364\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0190 - accuracy: 0.6364\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9682 - accuracy: 0.7273\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0147 - accuracy: 0.6364\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9482 - accuracy: 0.6364\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9502 - accuracy: 0.7273\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0187 - accuracy: 0.5455\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0453 - accuracy: 0.6364\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9748 - accuracy: 0.6364\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9555 - accuracy: 0.6364\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9365 - accuracy: 0.7273\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9701 - accuracy: 0.7273\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9009 - accuracy: 0.6364\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9447 - accuracy: 0.6364\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9631 - accuracy: 0.6364\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9358 - accuracy: 0.6364\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9180 - accuracy: 0.6364\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9435 - accuracy: 0.6364\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9482 - accuracy: 0.7273\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9449 - accuracy: 0.6364\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8669 - accuracy: 0.7273\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9155 - accuracy: 0.6364\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8503 - accuracy: 0.7273\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9315 - accuracy: 0.6364\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8392 - accuracy: 0.7273\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8712 - accuracy: 0.7273\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8891 - accuracy: 0.7273\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8661 - accuracy: 0.6364\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8784 - accuracy: 0.7273\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8396 - accuracy: 0.7273\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8227 - accuracy: 0.7273\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7955 - accuracy: 0.7273\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9080 - accuracy: 0.6364\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9045 - accuracy: 0.6364\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7778 - accuracy: 0.7273\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8517 - accuracy: 0.6364\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8801 - accuracy: 0.7273\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7749 - accuracy: 0.7273\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7874 - accuracy: 0.7273\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8768 - accuracy: 0.7273\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8822 - accuracy: 0.7273\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8036 - accuracy: 0.6364\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7649 - accuracy: 0.6364\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7741 - accuracy: 0.7273\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7797 - accuracy: 0.7273\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7621 - accuracy: 0.7273\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.6364\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7832 - accuracy: 0.6364\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7375 - accuracy: 0.7273\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7415 - accuracy: 0.7273\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8174 - accuracy: 0.7273\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7937 - accuracy: 0.7273\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8646 - accuracy: 0.6364\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7528 - accuracy: 0.7273\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7444 - accuracy: 0.7273\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7593 - accuracy: 0.7273\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7342 - accuracy: 0.7273\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7751 - accuracy: 0.7273\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7825 - accuracy: 0.7273\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7709 - accuracy: 0.7273\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7149 - accuracy: 0.7273\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6940 - accuracy: 0.7273\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7447 - accuracy: 0.7273\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7595 - accuracy: 0.7273\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7775 - accuracy: 0.7273\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7719 - accuracy: 0.7273\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7073 - accuracy: 0.7273\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7191 - accuracy: 0.7273\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6886 - accuracy: 0.7273\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7191 - accuracy: 0.7273\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7297 - accuracy: 0.7273\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7080 - accuracy: 0.7273\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6523 - accuracy: 0.7273\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7653 - accuracy: 0.7273\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7165 - accuracy: 0.7273\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6236 - accuracy: 0.7273\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6648 - accuracy: 0.7273\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7536 - accuracy: 0.7273\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8081 - accuracy: 0.6364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ae6cfb3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save('chatbot_model.h5')"
      ],
      "metadata": {
        "id": "9Ol6QZxozO6K"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to preprocess user input\n",
        "def preprocess_input(input):\n",
        "    # Tokenize input\n",
        "    input_words = input.split()\n",
        "    # Stem and lower case words\n",
        "    input_words = [stemmer.stem(w.lower()) for w in input_words]\n",
        "    # Create bag of words\n",
        "    input_bag = [0 for _ in range(len(words))]\n",
        "    for w in input_words:\n",
        "        if w in words:\n",
        "            input_bag[words.index(w)] = 1\n",
        "    # Return preprocessed input\n",
        "    return np.array(input_bag)"
      ],
      "metadata": {
        "id": "AOv5ryor0RIt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(input):\n",
        "    # Preprocess input\n",
        "    input_bag = preprocess_input(input)\n",
        "    # Use model to predict output\n",
        "    output = model.predict(np.array([input_bag]))[0]\n",
        "    # Get index of highest probability\n",
        "    index = np.argmax(output)\n",
        "    # Get tag for predicted intent\n",
        "    tag = labels[index]\n",
        "    # Choose a random response from the chosen intent\n",
        "    responses = [i['responses'] for i in intents if i['tag']==tag]\n",
        "    if responses:\n",
        "        response = np.random.choice(responses[0])\n",
        "    else:\n",
        "        response = \"I'm sorry, I didn't understand that.\"\n",
        "    return response"
      ],
      "metadata": {
        "id": "OMa41imK0Spm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test chatbot\n",
        "while True:\n",
        "    input_text = input(\"You: \")\n",
        "    if input_text.lower() == 'quit':\n",
        "        break\n",
        "    response = generate_response(input_text)\n",
        "    print(\"Bot: \" + response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "9MneRTR00IIN",
        "outputId": "e60dc9f5-7b22-4100-b7aa-ab5be778cf38"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: hi\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Bot: Hello!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-8271eba0d22a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}